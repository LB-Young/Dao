# PyTorch Broadcast 规则详解

## 核心规则

### 1. 从右边开始对齐维度
```python
# 示例
a: (3, 4)
b: (4,)
# 对齐后
a: (3, 4)
b: (1, 4)  # 左边补1
# 结果: (3, 4)
```

### 2. 维度为1的会被扩展
```python
# 示例
a: (3, 1)
b: (1, 4)
# broadcast后
a: (3, 4)  # 第二维从1扩展到4
b: (3, 4)  # 第一维从1扩展到3
# 结果: (3, 4)
```

### 3. 缺失的维度在左边补1
```python
# 示例
a: (2, 3, 4)
b: (4,)
# 对齐过程
b: (4,) -> (1, 1, 4) -> (2, 3, 4)
```

## 在你的LayerNorm中的应用

```python
# 你的代码中
h: (batch, seq_len, dim)          # 例如 (2, 4, 3)
gamma: (dim,)                     # 例如 (3,)

# broadcast过程
gamma: (3,) -> (1, 1, 3) -> (2, 4, 3)

# 最终运算
result = gamma * normalized_h     # (2, 4, 3) * (2, 4, 3)
```

## 常见错误

❌ **不兼容的维度**
```python
a: (3, 4)
b: (2, 3)  # 无法broadcast，因为4 ≠ 3
```

✅ **正确的做法**
```python
a: (3, 4)
b: (1, 4)  # 可以broadcast，第一维1可以扩展到3
```